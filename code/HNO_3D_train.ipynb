{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4, 5\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "device = torch.device('cuda')\n",
    "device_ids = [0, 1]\n",
    "\n",
    "from timeit import default_timer\n",
    "from torch.nn import DataParallel\n",
    "from util.loss_func import LpLoss\n",
    "from util.HNO import UNO3D\n",
    "from util.load_data import get_chunk_data\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "fs = 20\n",
    "fn = fs / 2  # Nyquist frequency\n",
    "dt = 1 / fs\n",
    "start_time_in_seconds = -0.5\n",
    "end_time_in_seconds = 2.0\n",
    "T = round((end_time_in_seconds - start_time_in_seconds) / dt + 1)\n",
    "n_after_padding = T\n",
    "freqs = torch.arange(n_after_padding // 2 + 1) * fs / (n_after_padding - 1)\n",
    "ws = 2 * torch.pi * freqs\n",
    "freq_to_keep = list(range(5, torch.where(freqs>=6)[0][0].item() + 1))  # select non-trivial frequencies, eliminate those with little energy\n",
    "NF = len(freq_to_keep)\n",
    "\n",
    "nx, ny, nz = 64, 64, 64\n",
    "nstrain = 1  # number of training instances in time domain, number of data points is this * NF\n",
    "nsvalid = 1  # number of validation instances in time domain, number of data points is this * NF\n",
    "offset_valid = 1\n",
    "\n",
    "width = 32\n",
    "\n",
    "batch_size = 32\n",
    "in_channels = 5\n",
    "out_channels = 6\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNO3D(in_channels+3, width, pad=0)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "\n",
    "model = DataParallel(model, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in, train_out = get_chunk_data(offset=0, chunk_size=nstrain, \n",
    "                                     NF=NF, nx=nx, ny=ny, nz=nz, in_channels=in_channels, out_channels=out_channels,\n",
    "                                     inputpath=\"../data/input_S\", \n",
    "                                     outputpath=\"../data/output_S\")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        train_in,\n",
    "        train_out),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "valid_in, valid_out = get_chunk_data(offset=offset_valid, chunk_size=nsvalid, \n",
    "                                     NF=NF, nx=nx, ny=ny, nz=nz, in_channels=in_channels, out_channels=out_channels,\n",
    "                                     inputpath=\"../data/input_S\", \n",
    "                                     outputpath=\"../data/output_S\")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        valid_in,\n",
    "        valid_out),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = LpLoss(p=2, size_average=False)  \n",
    "L1 = LpLoss(p=1, size_average=False)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    t1 = default_timer()\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_rel_l2 = 0.0  \n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        L2_loss = L2(out, y)\n",
    "        L1_loss = L1(out, y)\n",
    "        loss = 0.9 * L1_loss + 0.1 * L2_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "                \n",
    "    train_loss /= train_out.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_rel_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            L2_loss = L2(out, y)\n",
    "            L1_loss = L1(out, y)\n",
    "            loss = 0.9 * L1_loss + 0.1 * L2_loss\n",
    "            valid_loss += loss.item() \n",
    "                \n",
    "    valid_loss /= valid_out.size(0)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    t2 = default_timer()\n",
    "\n",
    "    print(ep, (t2 - t1) / 60 / 60, train_loss, valid_loss)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
